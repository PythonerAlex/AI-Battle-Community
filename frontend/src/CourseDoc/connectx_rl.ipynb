{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7974ff1b",
   "metadata": {},
   "source": [
    "# ConnectX Reinforcement Learning (Skeleton)\n",
    "_Last updated: 2025-08-14 08:34 UTC_\n",
    "\n",
    "**Goals**\n",
    "- Define environment interface (state, actions, reward)\n",
    "- Implement a simple baseline agent (random/heuristic)\n",
    "- (Stretch) Train a DQN/Policy-Gradient agent and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d9163",
   "metadata": {},
   "source": [
    "## 0. Environment (simplified 6x7 Connect Four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ff4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "ROWS, COLS = 6, 7\n",
    "\n",
    "class ConnectXEnv:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((ROWS, COLS), dtype=int)  # 0 empty, 1 agent, -1 opponent\n",
    "        self.player = 1\n",
    "        return self.board.copy()\n",
    "\n",
    "    def valid_actions(self):\n",
    "        return [c for c in range(COLS) if self.board[0, c] == 0]\n",
    "\n",
    "    def step(self, action):\n",
    "        if action not in self.valid_actions():\n",
    "            return self.board.copy(), -10.0, True, {\"illegal\": True}\n",
    "        # drop piece\n",
    "        r = ROWS-1\n",
    "        while r>=0 and self.board[r, action] != 0:\n",
    "            r -= 1\n",
    "        self.board[r, action] = self.player\n",
    "        reward, done = self._check_terminal(self.player)\n",
    "        self.player *= -1  # switch player\n",
    "        return self.board.copy(), reward, done, {}\n",
    "\n",
    "    def _check_terminal(self, p):\n",
    "        # win = +1 for p (agent), -1 when opponent wins (from agent perspective)\n",
    "        lines = []\n",
    "        b = self.board == p\n",
    "        # horiz\n",
    "        for r in range(ROWS):\n",
    "            for c in range(COLS-3):\n",
    "                if b[r, c:c+4].all(): return (1.0 if p==1 else -1.0), True\n",
    "        # vert\n",
    "        for r in range(ROWS-3):\n",
    "            for c in range(COLS):\n",
    "                if b[r:r+4, c].all(): return (1.0 if p==1 else -1.0), True\n",
    "        # diag         for r in range(ROWS-3):\n",
    "            for c in range(COLS-3):\n",
    "                if all(b[r+i, c+i] for i in range(4)): return (1.0 if p==1 else -1.0), True\n",
    "        # diag /\n",
    "        for r in range(3, ROWS):\n",
    "            for c in range(COLS-3):\n",
    "                if all(b[r-i, c+i] for i in range(4)): return (1.0 if p==1 else -1.0), True\n",
    "        # draw?\n",
    "        if (self.board != 0).all():\n",
    "            return 0.0, True\n",
    "        return 0.0, False\n",
    "\n",
    "env = ConnectXEnv()\n",
    "state = env.reset()\n",
    "state, env.valid_actions()[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2399835",
   "metadata": {},
   "source": [
    "## 1. Random / Heuristic Agent (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773adb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "def random_agent(obs):\n",
    "    acts = env.valid_actions()\n",
    "    return random.choice(acts) if acts else 0\n",
    "\n",
    "# Play one game vs random opponent\n",
    "obs = env.reset()\n",
    "done = False\n",
    "moves = 0\n",
    "while not done and moves < 100:\n",
    "    action = random_agent(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if done: break\n",
    "    # opponent\n",
    "    action_op = random_agent(obs)\n",
    "    obs, reward_op, done, info = env.step(action_op)\n",
    "    moves += 1\n",
    "\n",
    "reward, done, moves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98c129",
   "metadata": {},
   "source": [
    "## 2. (Stretch) DQN Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dde401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pseudocode outline for students to fill:\n",
    "# - Build a small CNN/MLP over board state (6x7)\n",
    "# - Experience replay buffer\n",
    "# - epsilon-greedy policy\n",
    "# - target network updates\n",
    "# Tip: transform board for 'current player' perspective to simplify value function.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
